一定要准备好以下问题：

# 一、自我介绍

你好，我叫刘稳。

- 2020年硕士毕业于南京邮电大学，之后一直在中国移动软件技术有限公司工作。
- 目前是在做数据库产品的业务开发，核心职责是 负责组内MySQL产品的订退改续以及容量管理工作，主要成就是 XXX。
- 技术栈：Go/java + MySQL/Redis/Mongo + RocketMQ/Kafka
- 我也积极参与分享，在CSDN上以博客方式分享自己的工作与学习经验，阅读量超20W+。
- 近期关注到贵公司在招聘 XXX，我认为我和这个岗位比较契合，相比其它候选人，我认为我的优势在于 XX。
- 后面随便补一点你觉得值得一提的其它事情。

# 二、项目介绍

- 进销存系统

- 统一网关emop-gateway系统是我们组的核心系统，它主要解决对接第三方平台，如移动云平台【op/mop】、计费模块【EBOSS】、运维平台【OPS】等第三方平台。
  它的核心难点是要保证高可用下的数据一致性。 为此我将整个模块做成了一个对外的网关，为业务方屏蔽了第三方平台的差异。并且在这基础上，
  加入了统一的服务治理、容错、鉴权等措施，可用性提高到了 四个9，和原本比起来出错率下降了90%。
  同时我还设计了一个支持测试的mock服务，使得开发和测试效率提高了20%。因此当年绩效比较好，是同批校招中第一个竞聘升岗。

- 认证模块

# 三、为什么选择来我们公司？

- 上海：
- 南京：
- 合肥：

- 公司：
- 个人：
- 家庭：

# 四、工作过程中遇到过哪些问题？最大的挑战是什么？

- RwMutex死锁问题排查：https://blog.csdn.net/qq_41822345/article/details/125907670
- 批量插入数据优化：https://mp.weixin.qq.com/s/-r8NxSuTprK2eS5vyjn31A
- 杭研慢sql问题

# 五、项目中核心困难？怎么解决的？

- 发现问题→分析问题→提出方案→取得效果。

- 案例一、Order访问元数据库超时问题排查——order连接mysql异常：i/o timeout 或者 invalid connection 报错。
  1、定时备份导致IO使用率高，引发连接异常。general-log定时归档导致IO使用率高。
  2、mysql所在宿主机内核软死锁(soft lockup) 导致主从切换引发的连接异常，该问题可能是由于虚机所在的宿主机的CPU负载较高或磁盘IO太高所致，
  虚拟机层面无法避免。迁移到物理机。
  3、代码层面：代码层面使用gorm连接池，但是未配置相关参数，导致每次查询基本都会建立新连接，频繁的创建新连接，可能会导致连接异常。
  DB.DB().SetConnMaxLifetime(600)    //连接最大存活时长 【数据库连接达到600s后关闭，reuse重用前判断是否超过600s，如果超过，则重建】
  DB.DB().SetConnMaxIdleTime(300)    //连接空闲超时时长 【闲时连接达到300s也关闭】
  DB.DB().SetMaxOpenConns(300)       //连接池最大连接数
  DB.DB().SetMaxIdleConns(20)        //连接池最大空闲连接数

- 案例二、杭研慢sql问题排查
  背景：
  客户业务侧会偶发出现慢SQL日志输出，一周大概100条慢SQL左右。
  客户业务侧通过配置了Druid的慢SQL功能记录相关日志，如下是客户在平台上抓取慢SQL日志后的展示：
  日志中包含了业务节点IP，容器IP，SQL执行时长，详细SQL和对应时间点。

根据客户提供的慢SQL信息，去所有后端MySQL节点上排查是否存在对应的慢日志：

1. 针对业务侧凌晨1-2点批量出现的慢SQL，可以在后端MySQL节点上找到对应的慢日志记录。
2. 针对业务侧其他时间点出现的慢SQL，未在后端MySQL节点上找到对应的慢日志记录。
   针对情况1：因为MySQL中本身也记录了慢SQL，所以肯定是由于性能引发的问题，根据排查，发现凌晨1-2点，MySQL实例节点会出现IOPS飙高的问题，
   此时读写流量激增，会影响到SQL执行效率。通过后台运行监控脚本，确认IOPS飙高是因为其他备库实例备份导致，通过限制备份IOPS后，此类问题基本解决，
   凌晨1-2点间不会因为备份而产生慢SQL。
   针对情况2：猜测不是MySQL自身的问题，因为慢日志中并没有发现对应的慢SQL。后在sre运维人员的配合下通过全链路抓包发现：从全链路抓包分析慢SQL来看，
   耗时主要是在客户通过云主机自建的K8S内部，怀疑是经过客户自建K8S中网络转发有问题，导致SQL从云主机发包已经慢了5秒，进而引发慢SQL。

# 六、你的缺点？

对我来说，我个是比较着急的人，急性子。所以，我最大的问题就是在推进一些事的时候，会忽略别人的感受。当压力变大的时候，我甚至会说出一些别人
难以接受的话（俗话说的情商为零）。这个没什么不好意思承认的，我这么多年来也在改进自己。

# 七、你的优势？

个人优势：公有云、厂商管理经验。
2022年获得了计算机技术与软件专业资格证书-软件设计师中级证书。

# 八、有没有MySQL调优经验？ 

MySQL调优场景描述【从部署到上线】

可以反问几个问题来确认需求：单主多从、16C64G1TB固态盘

【答题思路：io线程+bufferpool+表空间文件+同步配置+binlog开启+表结构合理化+压测提高缓冲命中+binlog cache_size调整】

- 1.首先，第一步在MySQL的安装部署阶段，进行参数调优【DBA运维】：
    - 参数1：IO线程[分为read_io和write_io线程]【MySQL后台有四个线程：Matser线程、IO线程、purge线程、page_cleaner线程】默认为4个，将其调到6个尽最大可能利用多核CPU；
    - 参数2：innodb_buffer_pool_size默认128M，预先调整为64G的25%，后面可以将其根据业务量的大小调整到64G的75%；
    - 参数3：innodb_buffer_pool_instance默认为1。可以调整为2或者4来作为缓冲池的个数，可以达到一个负载均衡的效果。
    - 参数4：表空间参数，innodb_file_per_table，默认关闭。应该打开，避免单个文件越大。索引越慢，也能达到物理文件的一个负载均衡的效果。
    - 参数5：innodb_data_path开启多个目录。开启表空间文件参数后，除了数据、数据的索引、插入缓冲数据每个表各占用一个文件，其它的数据比如：回滚段数据、事务数据等还是在共享表空间里，开启innodb_data_path的多个目录可以将这些数据负载到多个目录下。
    - 参数6：对于单主多从，binlog默认关闭，需要开启主的binlog。另外将事务隔离级别设置为rc，基于rbr模式进行主从复制，将lock_mod设置为2，以互斥量形式进行id的分发，提高插入性能。
    - 参数7：双一半同步设置：redolog的刷盘机制参数： innodb_flush_log_at_trx_commit为1——提交事务的时候将 redo 日志写入磁盘中（设置为1表示提交事务的时候，就必须把 redo log 从内存刷入到磁盘文件里去）；binlog的刷盘机制参数：sync_binlog —— 用来控制数据库的binlog刷到磁盘上（设置为1表示每次事务提交，MySQL都会把binlog刷下去，是最安全但是性能损耗最大的设置）
    - 参数8：开启线程池参数one-thread-per-connection。 开启线程池可以很大程度上能够避免因无法预测的热点数据导致宕机的事件发生。开启了1024个客户端，同时发送sql请求，mysql实例的qps也能稳定在最高值12000左右，相比于原来未开启线程池时的qps在1200左右，提高了9倍。 阿里云rds版本更新中有说明，本次更新数据库实例qps提高了数十倍，实际上就是开启了线程池，在多客户端请求下，qps稳定在最大值。

- 2.其次，第二步在业务开发阶段，数据库表设计【程序员】：

  比如严格控制每个字段的大小，尽可能保证B+树的高闪出性；根据业务需求进行索引设计；

  根据二级索引的设计测评是否需要开启5.6或者5.7的mrr优化，调整read_rnd_buffer_size。

  【Multi-Range Read，即多范围读取，主要解决的是当二级索引取出索引值后再去聚集索引中取行可能会造成大量的磁盘随机IO的问题，通过在内存缓冲区的一次排序，将随机I/O变为顺序I/O，提高】

- 3.最后，第三步是在压测阶段：

  开启慢查询日志slow_query_log【生产环境需要关闭】，根据具体的业务情况设置long_query_time，超过 long_query_time的sql会被记录下来。

  用explain分析这些耗时的sql语句，从而针对性优化。

  另外，压测过程中，通过执行show global status可以查看innodb缓冲池的命中率： 缓冲池的读取次数/磁盘的读取次数，如果该值小于99%【最优值】，则需要适当的调整缓冲池innodb_buffer_pool_size的大小。



