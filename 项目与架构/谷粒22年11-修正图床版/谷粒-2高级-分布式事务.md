分布式事务

另外一篇分布式事务笔记：https://blog.csdn.net/hancoder/article/details/120213532

## 一、谷粒生成需求

```
订单服务下订单---------\
库存服务锁库存---------->分布式事务
用户服务扣减积分-------/
```

事务保证：

1、订单服务异常，库存锁定不运行，全部回滚，撤销操作
2、库存服务事务自治，锁定失败全部回滚，订单感受到，继续回滚
3、库存服务锁定成功了，但是网络原因返回数据途中问题？
4、库存服务锁定成功了，库存服务下面的逻辑发生故障，订单回滚了，怎么处理？

利用消息队列实现最终一致

库存服务锁定成功后发给消息队列消息（当前库存工作单），过段时间自动解锁，解锁时先查询订单的支付状态。解锁成功修改库存工作单详情项状态为已解锁

- 1、远程服务假失败：远程服务其实成功了，由于网络故障等没有返回导致：订单回滚，库存却扣减
- 2、远程服务执行完成，下面的其他方法出现问题导致：已执行的远程请求，肯定不能回滚  

#### 事务和AOP注意点

事务传播问题中，传播后事务设置还是原来的，如果不想用原来设置，必须new事务

注意同类中调用的话，被调用事务会失效，原因在于aop。事务基于代理，同对象的方法动态代理都是同一个。解决方案是使用代理对象调用。引用aop-starter后，使用aspectJ，开启`AspectJ动态代理`，原来`默认使用的是jdk动态代理。`

使用`@EnableAspectJAutoProxy(exposeProxy=true)`后，就取代了`jdk动态代理`。它没有接口也可以创建动态代理。设置true是为了对外暴露代理对象。
`AopContext.currentProxy()`然后强转，就是当前代理对象。

```java
public interface AService {  
    public void a();  
    public void b();  
}  

@Service()  
public class AServiceImpl1 implements AService{  
    @Transactional(propagation = Propagation.REQUIRED)  
    public void a() {  
        this.b();  
    }  
    @Transactional(propagation = Propagation.REQUIRES_NEW)  
    public void b() {  
    }  
} 
此处的this指向目标对象，因此调用this.b()将不会执行b事务切面，即不会执行事务增强，
    因此b方法的事务定义“@Transactional(propagation = Propagation.REQUIRES_NEW)”将不会实施，
    即结果是b和a方法的事务定义是一样的（我们可以看到事务切面只对a方法进行了事务增强，没有对b方法进行增强）
    
    
Q1：b中的事务会不会生效？
A1：不会，a的事务会生效，b中不会有事务，因为a中调用b属于内部调用，没有通过代理，所以不会有事务产生。
Q2：如果想要b中有事务存在，要如何做？
A2：<aop:aspectj-autoproxy expose-proxy="true"> ，设置expose-proxy属性为true，将代理暴露出来，使用AopContext.currentProxy()获取当前代理，将this.b()改为((UserService)AopContext.currentProxy()).b()
```

解决方案：

```java
public void a() {  
    ((AService) AopContext.currentProxy()).b();//即调用AOP代理对象的b方法即可执行事务切面进行事务增强  
} 
```



## 二、分布式理论

第二章节可以直接去https://blog.csdn.net/hancoder/article/details/120213532 看，本篇内容都挪到那里面了，看回来后从第四章接着看

### 1、CAP理论

在另外的笔记中

### 2、选举与同步理论

分布式一致性动画演示：http://thesecretlivesofdata.com/raft/

raft是一个实现分布式一致性的协议

结点的状态：

- follower
- candidate
- leader

选举leader：

- 默认都以follower状态启动，follower监听不到leader，就称为一个candidate 
- 投票给自己，然后告诉其他人，同时也收到别人的投票信息。根据投票信息和投票信息里带的信息（如那个节点里的数据）
- 收到投票后，改选一个自己觉得最靠谱的。某一节点收到票数超过一半就变成leader

> raft有两个超时时间控制领导选举：
>
> - 选举超时：从follower到candidate的时间，150ms-300ms（自旋时间），这个时间段内没收到leader的心跳就变为候选者。
>   - 自旋时间结束后变成candidate，开始一轮新的选举（老师上课举的例子是）
>   - 投出去票后重新计时自旋
>   - leader就发送追加日志给follower，follower就正常
> - 消息发送的，心跳时间：如10ms，leader收到投票后，下一次心跳时就带上消息，follower收到消息后重置选举时间
>   - leader宕机，follower收不到心跳，开始新的选举
>

写数据：

- 接下来所有的数据都要先给leader，leader派发给follower
- 比如领导收到信息5后，领导先在leader的log中写入变化set 5。（上面的动态红颜色代表没提交），此时5还没提交，而是改了leader的log后，
- leader下一次心跳时，顺便带着信息让follower也去改变follower的log，follower写入日志成功后，发送确认ack 5给leader，
- leader收到大多数的ack后，leader就自己正式写入数据，然后告诉follower提交写入硬盘/内存吧（这个过程和响应客户端是同时的）。这个过程叫做日志复制（也有过半机制）
- 然后leader响应说集群写入好了

如果有的结点消息滞后了：

5台机器因为局域网隔离又分为3、2生成两个leader怎么办：

对于1,2结点那个leader，更新log后收不到大多数的ack（得超过1个ack），所以改log不成功，一直保存不成功

对于345结点的leader：收到消息后更新log并且收到ack过半且超过1个，成功保存。

此时网络又通了，以更高轮选举的leader为主，退位一个leader。那1，2结点日志都回滚，同步新leader的log。这样就都一致性了

另外注意：集群一般都是单数，因为有过半机制。比如原来集群6个机器，分为2半后，各3个，选leader时谁都拿不到6/2+1=4个投票，所以都没有leader

更多动画（可以自己选择宕机情况）raft.github.io

但一般都是保证AP，舍弃C

### 3、BASE

在另外的笔记中

### 4、分布式事务几种方案

> 看另外一篇笔记

1) 2PC模式(XA事务)

2) 柔性事务-TCC事务补偿型方案

3）柔性事务-最大努力通知型方案

4）柔性事务=可靠消息+最终一致性方案（异步确保型）

- RocketMQ事务消息
- 本地消息表



## 三、seata分布式事务

> 体验2pc两阶段提交。继续正例前面订单出错的逻辑

Seata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。

- AT模式主要关注多 DB 访问的数据一致性，当然也包括多服务下的多 DB 数据访问一致性问题
- TCC 模式主要关注业务拆分，在按照业务横向扩展资源时，解决微服务间调用的一致性问题



<img src="http://seata.io/img/solution.png" alt="img" style="zoom: 80%;" />



##### seata服务创建

> 数据源和undo_log表的配置见另一篇https://blog.csdn.net/hancoder/article/details/120213532

- 从 https://github.com/seata/seata/archive/v0.7.1.zip 下载服务器软件包senta-server-0.7.1，将其解压缩。作为TC

- 编译项目：

  - 下载后复制到guli项目下，然后在project structure--module中点击+号import module，选择项目里的seata

  - 会有报错，protobuf这个包找不到。在idea中安装`proto buffer editor`插件，重启idea（还找不到就重新编译一下，在mvn中找到seata-serializer子项目，点击protobuf里的compile选项。有个grpc的test报错，先全注释掉）

  - 有一个server项目，找到注册中心配置`resource/registry.conf`，修改启动的nacos信息。可以修改注册中心和配置中心（先不用管`file.conf`）

    ```ini
    registry {
      # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa
       # 修改这个
      type = "nacos"
    
      nacos {
        # 修改这个
        serverAddr = "localhost:8848"
        namespace = "public"
        cluster = "default"
      }
    ```

  - 启动server下的主类

  - 在nacos中看到一个serverAddr服务



> 
>
> - file.conf 的 service.vgroup_mapping 配置必须和`spring.application.name`一致
>
> 在`GlobalTransactionAutoConfiguration`类中，默认会使用 `${spring.application.name}-fescar-service-group`作为服务名注册到 Seata Server上(每个小事务也要注册到tc上)，如果和`file.conf`中的配置不一致，会提示 `no available server to connect`错误
>
> 也可以通过配置yaml的 `spring.cloud.alibaba.seata.tx-service-group`修改后缀，但是必须和`file.conf`中的配置保持一致

与上面配置数据源的方式等价，这么配置

```java
@Configuration
public class MySeataConfig {
    @Autowired
    DataSourceProperties dataSourceProperties;

    @Bean
    public DataSource dataSource(DataSourceProperties dataSourceProperties) {

        HikariDataSource dataSource = dataSourceProperties.initializeDataSourceBuilder().type(HikariDataSource.class).build();
        if (StringUtils.hasText(dataSourceProperties.getName())) {
            dataSource.setPoolName(dataSourceProperties.getName());
        }
        return new DataSourceProxy(dataSource);
    }
}
```

在order、ware中都配置好上面的配置

然后它还要求每个微服务要有`register.conf`和`file.conf`

将`register.conf`和`file.conf`复制到需要开启分布式事务的根目录，并修改`file.conf`

 `vgroup_mapping.${application.name}-fescar-service-group = "default"`

```shell
service {
  #vgroup->rgroup
  vgroup_mapping.gulimall-ware-fescar-service-group = "default"
  #only support single node  
  default.grouplist = "127.0.0.1:8091"
  #degrade current not support
  enableDegrade = false
  #disable
  disable = false
  #unit ms,s,m,h,d represents milliseconds, seconds, minutes, hours, days, default permanent
  max.commit.retry.timeout = "-1"
  max.rollback.retry.timeout = "-1"
}
```

在大事务上`@GlobalTransactional`，小事务上`@Transactional`即可

tcc也可以看samples。

但是上面使用的是AT模式，2pc不适用高并发。

发生了几次远程调用。去保护spu，适合使用at模式。

高并发，如下单，at模式有很多锁，影响效率。所以不使用at  tcc。使用消息方式
失败了之后发消息。库存服务本身也可以使用自动解锁模式。消息队列。
自动解锁：库存服务订阅消息队列，库存解锁发给消息队列

保存库存工作单和库存工作单详情，
锁定库存后数据库记录。后面的事务失败后看前面的库存，有没解锁的就解锁。
定期全部检索很麻烦，索引引入延迟队列。
锁库存后害怕订单失败，锁库存后发送给消息队列，只不过要暂存一会先别被消费。半小时以后再消费就可以知道大事务成功没有。



### Seata AT 模式

前提

- 基于支持本地 ACID 事务的关系型数据库。
- Java 应用，通过 JDBC 访问数据库。

##### 整体机制

两阶段提交协议的演变：

- 一阶段：业务数据和回滚日志记录在同一个本地事务中提交，释放本地锁和连接资源。
- 二阶段：
  - 提交异步化，非常快速地完成。
  - 回滚通过一阶段的回滚日志进行反向补偿。

##### 工作机制

以一个示例来说明整个 AT 分支的工作过程。

业务表：`product`

| Field | Type         | Key  |
| ----- | ------------ | ---- |
| id    | bigint(20)   | PRI  |
| name  | varchar(100) |      |
| since | varchar(100) |      |

AT 分支事务的业务逻辑：

```sql
update product set name = 'GTS' where name = 'TXC';
```

##### 一阶段

过程：

1. 解析 SQL：得到 SQL 的类型（UPDATE），表（product），条件（where name = 'TXC'）等相关的信息。
2. 查询前镜像：根据解析得到的条件信息，生成查询语句，定位数据。

```sql
select id, name, since from product where name = 'TXC';
```

得到前镜像：

| id   | name | since |
| ---- | ---- | ----- |
| 1    | TXC  | 2014  |

1. 执行业务 SQL：更新这条记录的 name 为 'GTS'。
2. 查询后镜像：根据前镜像的结果，通过 **主键** 定位数据。

```sql
select id, name, since from product where id = 1`;
```

得到后镜像：

| id   | name | since |
| ---- | ---- | ----- |
| 1    | GTS  | 2014  |

1. 插入回滚日志：把前后镜像数据以及业务 SQL 相关的信息组成一条回滚日志记录，插入到 `UNDO_LOG` 表中。

```json
{
	"branchId": 641789253,
	"undoItems": [{
		"afterImage": {
			"rows": [{
				"fields": [{
					"name": "id",
					"type": 4,
					"value": 1
				}, {
					"name": "name",
					"type": 12,
					"value": "GTS"
				}, {
					"name": "since",
					"type": 12,
					"value": "2014"
				}]
			}],
			"tableName": "product"
		},
		"beforeImage": {
			"rows": [{
				"fields": [{
					"name": "id",
					"type": 4,
					"value": 1
				}, {
					"name": "name",
					"type": 12,
					"value": "TXC"
				}, {
					"name": "since",
					"type": 12,
					"value": "2014"
				}]
			}],
			"tableName": "product"
		},
		"sqlType": "UPDATE"
	}],
	"xid": "xid:xxx"
}
```

1. 提交前，向 TC 注册分支：申请 `product` 表中，主键值等于 1 的记录的 **全局锁** 。
2. 本地事务提交：业务数据的更新和前面步骤中生成的 UNDO LOG 一并提交。
3. 将本地事务提交的结果上报给 TC。

##### 二阶段-回滚

1. 收到 TC 的分支回滚请求，开启一个本地事务，执行如下操作。
2. 通过 XID 和 Branch ID 查找到相应的 UNDO LOG 记录。
3. 数据校验：拿 UNDO LOG 中的后镜与当前数据进行比较，如果有不同，说明数据被当前全局事务之外的动作做了修改。这种情况，需要根据配置策略来做处理，详细的说明在另外的文档中介绍。
4. 根据 UNDO LOG 中的前镜像和业务 SQL 的相关信息生成并执行回滚的语句：

```sql
update product set name = 'TXC' where id = 1;
```

1. 提交本地事务。并把本地事务的执行结果（即分支事务回滚的结果）上报给 TC。

##### 二阶段-提交

1. 收到 TC 的分支提交请求，把请求放入一个异步任务的队列中，马上返回提交成功的结果给 TC。
2. 异步任务阶段的分支提交请求将异步和批量地删除相应 UNDO LOG 记录。

##### 附录

##### 回滚日志表

UNDO_LOG Table：不同数据库在类型上会略有差别。

以 MySQL 为例：

| Field         | Type         |
| ------------- | ------------ |
| branch_id     | bigint PK    |
| xid           | varchar(100) |
| context       | varchar(128) |
| rollback_info | longblob     |
| log_status    | tinyint      |
| log_created   | datetime     |
| log_modified  | datetime     |

```sql
-- 注意此处0.7.0+ 增加字段 context
CREATE TABLE `undo_log` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `branch_id` bigint(20) NOT NULL,
  `xid` varchar(100) NOT NULL,
  `context` varchar(128) NOT NULL,
  `rollback_info` longblob NOT NULL,
  `log_status` int(11) NOT NULL,
  `log_created` datetime NOT NULL,
  `log_modified` datetime NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)
) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;
```

### Seata TCC 模式

见另外的笔记

### SEATA Saga 模式



Saga模式是SEATA提供的长事务解决方案，在Saga模式中，业务流程中每个参与者都提交本地事务，当出现某一个参与者失败则补偿前面已经成功的参与者，一阶段正向服务和二阶段补偿服务都由业务开发实现。

![Saga模式示意图](https://img.alicdn.com/tfs/TB1Y2kuw7T2gK0jSZFkXXcIQFXa-445-444.png)

理论基础：Hector & Kenneth 发表论⽂ Sagas （1987）

##### 适用场景：

- 业务流程长、业务流程多
- 参与者包含其它公司或遗留系统服务，无法提供 TCC 模式要求的三个接口

##### 优势：

- 一阶段提交本地事务，无锁，高性能
- 事件驱动架构，参与者可异步执行，高吞吐
- 补偿服务易于实现

##### 缺点：

- 不保证隔离性（应对方案见后面文档）



### Saga 设计原则

允许空补偿

防悬挂控制

幂等控制

>  见另外的笔记

### 注意扣款顺序

- 事务不保证隔离性, 在极端情况下可能由于脏写无法完成回滚操作, 比如举一个极端的例子, 分布式事务内先给用户A充值, 然后给用户B扣减余额, 如果在给A用户充值成功, 在事务提交以前, A用户把余额消费掉了, 如果事务发生回滚, 这时则没有办法进行补偿了。这就是缺乏隔离性造成的典型的问题, 实践中一般的应对方法是：
  - 业务流程设计时遵循“宁可长款, 不可短款”的原则, 长款意思是客户少了钱机构多了钱, 以机构信誉可以给客户退款, 反之则是短款, 少的钱可能追不回来了。所以在业务流程设计上一定是先扣款。
  - 有些业务场景可以允许让业务最终成功, 在回滚不了的情况下可以继续重试完成后面的流程, 所以状态机引擎除了提供“回滚”能力还需要提供“向前”恢复上下文继续执行的能力, 让业务最终执行成功, 达到最终一致性的目的。





### Seata XA 模式

前提：

- 支持XA 事务的数据库。
- Java 应用，通过 JDBC 访问数据库。

整体机制：观察下面图的事务ID和分支ID

在 Seata 定义的分布式事务框架内，利用事务资源（数据库、消息服务等）对 XA 协议的支持，以 XA 协议的机制来管理分支事务的一种 事务模式。

![img](https://img.alicdn.com/tfs/TB1hSpccIVl614jSZKPXXaGjpXa-1330-924.png)

##### 工作机制

##### 1. 整体运行机制

XA 模式 运行在 Seata 定义的事务框架内：

![xa-fw](https://img.alicdn.com/tfs/TB1uM2OaSslXu8jSZFuXXXg7FXa-1330-958.png)

- 执行阶段（E xecute）：
- - XA start/XA end/XA prepare + SQL + 注册分支
- 完成阶段（F inish）：
- - XA commit/XA rollback

##### 2. 数据源代理

XA 模式需要 XAConnection。

获取 XAConnection 两种方式：

- 方式一：要求开发者配置 XADataSource：给开发者增加了认知负担，需要为 XA 模式专门去学习和使用 XA 数据源，与 透明化 XA 编程模型的设计目标相违背。
- 方式二：根据开发者的普通 DataSource 来创建：对开发者比较友好，和 AT 模式使用一样，开发者完全不必关心 XA 层面的任何问题，保持本地编程模型即可。

我们优先设计实现第二种方式：数据源代理根据普通数据源中获取的普通 JDBC 连接创建出相应的 XAConnection。

类比 AT 模式的数据源代理机制，如下：

![ds1](https://img.alicdn.com/tfs/TB11_LJcggP7K4jSZFqXXamhVXa-1564-894.png)

但是，第二种方法有局限：无法保证兼容的正确性。

实际上，这种方法是在做数据库驱动程序要做的事情。不同的厂商、不同版本的数据库驱动实现机制是厂商私有的，我们只能保证在充分测试过的驱动程序上是正确的，开发者使用的驱动程序版本差异很可能造成机制的失效。

类比 AT 模式的数据源代理机制，如下：

![ds2](https://img.alicdn.com/tfs/TB1qJ57XZieb18jSZFvXXaI3FXa-1564-894.png)

代码数据源：

因为2PC会携带事务ID进行远程调用，以及写undo_log表，肯定跟普通的数据源是不一样的，所以我们代理一下数据源。因为springboot有自动配置，我们就按照自动配置自己代理下就好了

```java
@Bean
public DataSource dataSource(DataSourceProperties dataSourceProperties){
    HikariDataSource dataSource = dataSourceProperties.initializeDataSourceBuilder().type(HikariDataSource.class).build();
    if(StringUtils.hasText(dataSourceProperties.getName())){
        dataSource.setPoolName(dataSourceProperties.getName());
    }
    return new DataSourceProxy(dataSource);
}
```



##### 3. 全局事务ID和分支事务ID

XA start 需要 Xid 参数。

这个 Xid 需要和 Seata 全局事务的 XID 和 BranchId 关联起来，以便由 TC 驱动 XA 分支的提交或回滚。

目前 Seata 的 BranchId 是在分支注册过程，由 TC 统一生成的，所以 XA 模式分支注册的时机需要在 XA start 之前。

将来一个可能的优化方向：

把分支注册尽量延后。类似 AT 模式在本地事务提交之前才注册分支，避免分支执行失败情况下，没有意义的分支注册。

这个优化方向需要 BranchId 生成机制的变化来配合。BranchId 不通过分支注册过程生成，而是生成后再带着 BranchId 去注册分支。





## ==四、消息队列实现最终一致性==

![](https://i0.hdslb.com/bfs/album/72c2a095c2cbdc5951df3366eec0af1669edb37d.png)

上面这个流程并没有特别的设置，完全靠消息队列控制



#### (1) 定时任务的缺陷

<img src="https://i0.hdslb.com/bfs/album/9228adac3752521f1f4c6a77994bd0dbfbc70f21.png" style="zoom: 50%;" />

**为什么不能用定时任务完成？**

如果恰好在一次扫描后完成业务逻辑，那么就会等待两个扫描周期才能扫到过期的订单，不能保证时效性

<img src="https://i0.hdslb.com/bfs/album/d5f7c9e524e934d359bb7920247071a3aaf33d92.png" style="zoom:50%;" />

#### (2) 延迟队列

场景：比如未付款订单，超过一定时间后，系统自动取消订单并释放占有物品

常用解决方案：

- spring的schedule走时任务轮询数据库
  - 消耗系统内存、增加了数据库的压力、存在较大时间误差
- 解决：rabbitmq的消息TTL和死信Exchange结合 

订单关了之后40分钟后库存检查订单存在还是取消。

> 定时任务此外还有超时和检测时间段错开的情况(时效性问题)。最高等2倍的定时任务时间。
>
> 下订单延迟队列，
>
> 不要设置消息过期，要设置为队列过期方式。
>
> 节省一个交换机
>
> 使用bean方式创建交换机。
> 注意a

* 定义：延迟队列存储的对象肯定是对应的延时消息，所谓"延时消息"是指当消息被发送以后，并不想让消费者立即拿到消息，而是等待指定时间后，消费者才拿到这个消息进行消费。

* 实现：rabbitmq可以通过设置队列的`TTL`+死信路由实现延迟队列

  * TTL：RabbitMQ可以针对Queue设置x-expires 或者 针对Message设置 x-message-ttl，来控制消息的生存时间，如果超时(两者同时设置以最先到期的时间为准)，则消息变为dead letter(死信)

  * 死信路由DLX：RabbitMQ的Queue可以配置x-dead-letter-exchange 和x-dead-letter-routing-key（可选）两个参数，如果队列内出现了dead letter，则按照这两个参数重新路由转发到指定的队列。
    * x-dead-letter-exchange：出现dead letter之后将dead letter重新发送到指定exchange
    * x-dead-letter-routing-key：出现dead letter之后将dead letter重新按照指定的routing-key发送




![](https://i0.hdslb.com/bfs/album/8f06baff32b9b1b16f4e58e6b6df6c83abb23bba.png)

针对订单模块创建以上消息队列，创建订单时消息会被发送至队列`order.delay.queue`，经过`TTL`的时间后消息会变成死信以`order.release.order`的路由键经交换机转发至队列`order.release.order.queue`，再通过监听该队列的消息来实现过期订单的处理

#### (3) 订单逻辑

* 订单超时未支付触发订单过期状态修改与库存解锁

> 创建订单时消息会被发送至队列`order.delay.queue`，经过`TTL`的时间后消息会变成死信以`order.release.order`的路由键经交换机转发至队列`order.release.order.queue`，再通过监听该队列的消息来实现过期订单的处理
>
> * 如果该订单已支付，则无需处理
> * 否则说明该订单已过期，修改该订单的状态并通过路由键`order.release.other`发送消息至队列`stock.release.stock.queue`进行库存解锁

> 注意，这个地方还是得自己看一下，我为了形象表示可能并未按视频上的路由键什么的来。
>
> 下面是我的配置
>
> ```java
> // 本来想用ConfigurationProperties，
> // 但是在使用listener注解时无法注入队列字符串，所以只能用类了
> // 类的话就丢失了原来在nacos能动态更新的优点，但为了能方便使用，我们还是在这里定义吧
> public class RabbitInfo {
> 
>     public static class Order{
>         // 其实厂里应该大写，但是我们为了区分，这里也不改了
>         public static final String exchange = "order-event-exchange";
>         public static final String delayQueue = "order.delay.queue";
>         public static final String delayRoutingKey = "order.locked";
>         public static final String releaseQueue = "order.release.queue";
>         public static final String releaseRoutingKey="order.release";
>         public static final int ttl = 900000;
>     }
>     public static class Stock{
>         public static final String exchange="stock-event-exchange";
>         public static final String delayQueue="stock.delay.queue";
>         public static final String delayRoutingKey="stock.locked";
>         public static final String releaseQueue="stock.release.queue";
>         public static final String releaseRoutingKey="stock.release.queue";
>         public static final int ttl = 900000;
>     }
> }
> ```
>
> 

库存锁定后延迟检查是否需要解锁库存

* 库存锁定后延迟检查是否需要解锁库存

> 在库存锁定后通过`路由键stock.locked`发送至`延迟队列stock.delay.queue`，延迟时间到，死信通过`路由键stock.release`转发至`stock.release.stock.queue`,通过监听该队列进行判断当前订单状态，来确定库存是否需要解锁

* 由于`关闭订单`和`库存解锁`都有可能被执行多次，因此要保证业务逻辑的幂等性，在执行业务是重新查询当前的状态进行判断
* 订单关闭和库存解锁都会进行库存解锁的操作，来确保业务异常或者订单过期时库存会被可靠解锁

#### (4) 自动创建交换机和队列

在ware和order中配置好pom、yaml、@EnableRabbit

> 这个地方我在版本迭代中改过，如有不匹配的自己尝试吧，自己研究下不难

* 订单模块

```java
/**
 * Description：容器中的所有bean都会自动创建到RabbitMQ中 [RabbitMQ没有这个队列、交换机、绑定]
 * date：2020/7/3 17:03
 * 创建交换机、队列、bind
 */
@Configuration
public class OrderMQConfig {

	/**
	 * String name, boolean durable, boolean autoDelete, Map<String, Object> arguments
	 * @return
	 */
	@Bean
	public Exchange orderEventExchange(){
		return new TopicExchange( RabbitInfo.Order.exchange,
				true, false);
	}


	/**
	 * String name, boolean durable, boolean exclusive,
	 * boolean autoDelete,
	 * @Nullable Map<String, Object> arguments
	 */
	@Bean
	public Queue orderDelayQueue(){
		Map<String ,Object> arguments = new HashMap<>();
		arguments.put("x-dead-letter-exchange", RabbitInfo.Order.exchange);
		// 死信队列的re路由key
		arguments.put("x-dead-letter-routing-key",  RabbitInfo.Order.releaseRoutingKey);
		arguments.put("x-message-ttl",  RabbitInfo.Order.ttl);
		Queue queue = new Queue( RabbitInfo.Order.delayQueue, true, false, false, arguments);
		return queue;
	}

	@Bean
	public Queue orderReleaseOrderQueue(){
		Queue queue = new Queue( RabbitInfo.Order.releaseQueue,
				true,
				false,
				false);
		return queue;
	}


	/**
	 * String destination, DestinationType destinationType, String exchange, String routingKey, @Nullable Map<String, Object> arguments
	 */
	@Bean
	public Binding orderCreateOrderBinding(){

		return new Binding( RabbitInfo.Order.delayQueue, Binding.DestinationType.QUEUE,
				RabbitInfo.Order.exchange,  RabbitInfo.Order.delayRoutingKey, null);
	}

	@Bean
	public Binding orderReleaseOrderBinding(){

		return new Binding( RabbitInfo.Order.releaseQueue, Binding.DestinationType.QUEUE,
				RabbitInfo.Order.exchange,  RabbitInfo.Order.releaseRoutingKey, null);
	}

	/**
	 * 订单释放直接和库存释放进行绑定
	 */
	@Bean
	public Binding orderReleaseOtherBinding(){

		return new Binding(RabbitInfo.Order.releaseQueue, Binding.DestinationType.QUEUE,
				RabbitInfo.Order.exchange,
				baseRoutingKey, null);
	}

//	@Bean
//	public Queue orderSecKillQueue(){
//		return new Queue(RabbitInfo.SecKill.delayQueue,
//				true, false, false);
//	}
//
//	@Bean
//	public Binding orderSecKillQueueBinding(){
//		return new Binding(RabbitInfo.SecKill.delayQueue, Binding.DestinationType.QUEUE,
//				RabbitInfo.Order.exchange, RabbitInfo.SecKill.delayRoutingKey, null);
//	}
}

```



* 库存模块

```java
@Configuration
public class WareRabbitConfig {

	/**
	 * 消息转换器
	 */
	@Bean
	public MessageConverter messageConverter(){
		return new Jackson2JsonMessageConverter();
	}

	/**
	 * String name, boolean durable, boolean autoDelete, Map<String, Object> arguments
	 */
	@Bean
	public Exchange stockEventExchange(){

		return new TopicExchange(RabbitInfo.Stock.exchange, 
				true, false);
	}

	/**
	 * String name, boolean durable, boolean exclusive, boolean autoDelete, @Nullable Map<String, Object> arguments
	 */
	@Bean
	public Queue stockReleaseQueue(){
		return new Queue(RabbitInfo.Stock.releaseQueue, true,
				false, false);
	}

	@Bean
	public Queue stockDelayQueue(){

		Map<String, Object> args = new HashMap<>();
		// 信死了 交给 [stock-event-exchange] 交换机
		args.put("x-dead-letter-exchange",RabbitInfo.Stock.exchange);
		// 死信路由
		args.put("x-dead-letter-routing-key",RabbitInfo.Stock.releaseRoutingKey);
		args.put("x-message-ttl", RabbitInfo.Stock.ttl);

		return new Queue(RabbitInfo.Stock.delayQueue, true,
				false, false, args);
	}

	/**
	 * 延时队列的绑定关系
	 * String destination, DestinationType destinationType, String exchange, String routingKey, @Nullable Map<String, Object> arguments
	 */
	@Bean
	public Binding stockLockedBinding(){

		return new Binding(RabbitInfo.Stock.delayQueue, Binding.DestinationType.QUEUE,
				RabbitInfo.Stock.exchange, RabbitInfo.Stock.delayRoutingKey, null);
	}

	/**
	 * 普通队列的绑定关系
	 * String destination, DestinationType destinationType, String exchange, String routingKey, @Nullable Map<String, Object> arguments
	 */
	@Bean
	public Binding stockLockedReleaseBinding(){

		return new Binding(RabbitInfo.Stock.releaseQueue,Binding.DestinationType.QUEUE,
				RabbitInfo.Stock.exchange,RabbitInfo.Stock.baseRoutingKey
				, null);
	}

}

```



#### (5) 库存回滚解锁

![](https://i0.hdslb.com/bfs/album/cf307afd8fc216266719f5f6512d62379c183335.png)

##### 1）库存锁定

在库存锁定是添加以下逻辑

* 由于可能订单回滚的情况，所以为了能够得到库存锁定的信息，在锁定时需要记录库存工作单，其中包括订单信息和锁定库存时的信息(仓库id，商品id，锁了几件...)
* 在锁定成功后，向延迟队列发消息，带上库存锁定的相关信息

逻辑：

- 遍历订单项，遍历每个订单项的每个库存，直到锁到库存

- 发消息后库存回滚也没关系，用id是查不到数据库的

- 锁库存的sql

  ```xml
  <update id="lockSkuStock">
      UPDATE `wms_ware_sku` SET stock_locked = stock_locked + #{num}
      WHERE sku_id = #{skuId} 
      AND ware_id = #{wareId}
      AND stock-stock_locked >= #{num}
  </update>
  ```

  

```java
@Override
public void unlockStock(StockLockedTo to) {
    log.info("\n收到解锁库存的消息");
    // 库存id
    Long id = to.getId();
    StockDetailTo detailTo = to.getDetailTo();
    Long detailId = detailTo.getId();
    /**
         * 流程图：![](https://i0.hdslb.com/bfs/album/cf307afd8fc216266719f5f6512d62379c183335.png)
         * 解锁库存
         * 	查询数据库关系这个订单的详情
         * 		有: 证明库存锁定成功
         * 			1.没有这个订单, 必须解锁
         * 			2.有这个订单 不是解锁库存
         * 				订单状态：已取消,解锁库存
         * 				没取消：不能解锁	;
         * 		没有：就是库存锁定失败， 库存回滚了 这种情况无需回滚
         */
    WareOrderTaskDetailEntity byId = orderTaskDetailService.getById(detailId);
    if (byId != null) {
        // 解锁
        WareOrderTaskEntity taskEntity = orderTaskService.getById(id);
        String orderSn = taskEntity.getOrderSn();
        // 根据订单号 查询订单状态 已取消才解锁库存
        R orderStatus = orderFeignService.getOrderStatus(orderSn);
        if (orderStatus.getCode() == 0) {
            // 订单数据返回成功
            OrderVo orderVo = orderStatus.getData(new TypeReference<OrderVo>() {
            });
            // 订单不存在或订单已取消
            if (orderVo == null || orderVo.getStatus() == OrderStatusEnum.CANCLED.getCode()) {
                // 订单已取消 状态1 已锁定  这样才可以解锁
                if (byId.getLockStatus() == 1) {
                    unLock(detailTo.getSkuId(), detailTo.getWareId(), detailTo.getSkuNum(), detailId);
                }
            }
        } else {
            // 消息拒绝 重新放回队列 让别人继续消费解锁
            throw new RuntimeException("远程服务失败");
        }
    } else {
        // 无需解锁
    }
}
```

什么编写了发送消息队列的逻辑，下面写接收消息队列后还原库存的逻辑

##### 2）接收消息

* 延迟队列会将过期的消息路由至`"stock.release.queue"`,通过监听该队列实现库存的解锁
* 为保证消息的可靠到达，我们使用手动确认消息的模式，在解锁成功后确认消息，若出现异常则重新归队

```java
@Service
@RabbitListener(queues = RabbitInfo.Stock.releaseQueue)
public class StockReleaseListener {

    @Autowired
    private WareSkuService wareSkuService;

    /**
	 * 下单成功 库存解锁 接下来业务调用失败
	 *
	 *  只要解锁库存消息失败 一定要告诉服务解锁失败
	 */
    @RabbitHandler
    public void handleStockLockedRelease(StockLockedTo to,
                                         Message message,
                                         Channel channel) throws IOException {
        try {
            wareSkuService.unlockStock(to); // 要根据id
            // 执行成功的 回复 [仅回复自己的消息]
            channel.basicAck(message.getMessageProperties().getDeliveryTag(), false);
        } catch (Exception e) {
            channel.basicReject(message.getMessageProperties().getDeliveryTag(), true);
        }
    }
```

##### 3）库存解锁

![](https://i0.hdslb.com/bfs/album/cf307afd8fc216266719f5f6512d62379c183335.png)

* 如果工作单详情不为空，说明该库存锁定成功
  * 查询最新的订单状态，
    * 如果订单不存在，说明订单提交出现异常回滚，必须回滚库存
    * 如果订单存在（但订单处于已取消的状态），也回滚库存
* 如果工作单详情为空，说明库存未锁定，自然无需解锁
* 为保证幂等性，我们分别对订单的状态和工作单的状态都进行了判断，只有当订单过期且工作单显示当前库存处于锁定的状态时，才进行库存的解锁

解锁库存核心sql

```xml
<update id="unlockStock">
    UPDATE `wms_ware_sku` 
    SET stock_locked = stock_locked - #{num}
    WHERE sku_id = #{skuId} 
    AND ware_id = #{wareId}
</update>
```

```java
/**
     * 流程图：![](https://i0.hdslb.com/bfs/album/cf307afd8fc216266719f5f6512d62379c183335.png)
     * 解锁库存
     * 	查询数据库关系这个订单的详情
     * 		有: 证明库存锁定成功
     * 			1.没有这个订单, 必须解锁
     * 			2.有这个订单 不是解锁库存
     * 				订单状态：已取消,解锁库存
     * 				没取消：不能解锁	;
     * 		没有：就是库存锁定失败， 库存回滚了 这种情况无需回滚
     */
    @Override
    public void unlockStock(StockLockedTo to) {
        log.info("\n收到解锁库存的消息");
        // 库存id
        Long id = to.getId();
        StockDetailTo detailTo = to.getDetailTo();
        Long detailId = detailTo.getId();

        WareOrderTaskDetailEntity byId = orderTaskDetailService.getById(detailId);
        if (byId != null) {
            // 解锁
            WareOrderTaskEntity taskEntity = orderTaskService.getById(id);
            String orderSn = taskEntity.getOrderSn();
            // 根据订单号 查询订单状态 已取消才解锁库存
            R orderStatus = orderFeignService.getOrderStatus(orderSn);
            if (orderStatus.getCode() == 0) {
                // 订单数据返回成功
                OrderVo orderVo = orderStatus.getData(new TypeReference<OrderVo>() {
                });
                // 订单不存在或订单已取消
                if (orderVo == null || orderVo.getStatus() == OrderStatusEnum.CANCLED.getCode()) {
                    // 订单已取消 状态1 已锁定  这样才可以解锁
                    if (byId.getLockStatus() == 1) {
                        unLock(detailTo.getSkuId(), detailTo.getWareId(), detailTo.getSkuNum(), detailId);
                    }
                }
            } else {
                // 消息拒绝 重新放回队列 让别人继续消费解锁
                throw new RuntimeException("远程服务失败");
            }
        } else {
            // 无需解锁
        }
    }
/**
     * 解锁库存
     */
private void unLock(Long skuId,Long wareId, Integer num, Long taskDeailId){
    // 更新库存
    wareSkuDao.unlockStock(skuId, wareId, num);
    // 更新库存工作单的状态
    WareOrderTaskDetailEntity detailEntity = new WareOrderTaskDetailEntity();
    detailEntity.setId(taskDeailId);
    detailEntity.setLockStatus(2);
    orderTaskDetailService.updateById(detailEntity);
}
```

注意远程调用还需要登录的问题，所以设置拦截器不拦截 order/order/status/{orderSn}。

```java
@Override
public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {

    String uri = request.getRequestURI();
    // 这个请求直接放行
    boolean match = new AntPathMatcher().match("/order/order/status/**", uri);
    if(match){
        return true;
    }
```

远程调用不携带Cookie的问题，可以参考GlFeignConfig解决。但是可能是因为MQ监听器属于多线程的原因？（监听器并不受访问用户影响，而是一直在后台进行）导致这种方法可能不成功，所以可能还是得按老师的来，放来Order里的查询拦截



#### (6) 定时关单

前面的定时回滚内存，现在要进行的内容是过30min后把没支付的单子改成已取消

前面回滚库存的时机是30min后查看订单的状态，比如是已取消或者未支付，直接解锁库存

而订单关单只是关订单而已，不要去解锁库存，否则就有冲突了

提交订单的时候发了个消息队列

```java
@Transactional
@Override
public SubmitOrderResponseVo submitOrder(OrderSubmitVo submitVo) {

    //提交订单的业务处理。。。

    R r = wmsFeignService.orderLockStock(lockVo);
    if (r.getCode() == 0) {
        // 库存足够 锁定成功 给MQ发送订单消息，到时为支付则取消
        submitVo.setOrderEntity(order.getOrder());
        // 这个地方值得想一下锁库存和发MQ直接的事务性
        rabbitTemplate.convertAndSend(RabbitInfo.Order.exchange,
                                      RabbitInfo.Order.delayQueue,
                                      order.getOrder());
        saveOrder(order);
    } 
```

##### 2) 监听队列

创建订单的消息会进入延迟队列，最终发送至队列`order.release.order.queue`，因此我们对该队列进行监听，进行订单的关闭

```java
@Service
@RabbitListener(queues = RabbitInfo.Order.releaseQueue)
public class OrderCloseListener {

    @Autowired
    private OrderService orderService;

    @RabbitHandler
    public void listener(OrderEntity entity,
                         Channel channel,
                         Message message) throws IOException {
        try {
            orderService.closeOrder(entity);
            // 手动调用支付宝收单
            channel.basicAck(message.getMessageProperties().getDeliveryTag(),false);
        } catch (Exception e) {
            channel.basicReject(message.getMessageProperties().getDeliveryTag(),true);
        }
    }
}
```

##### 3) 关闭订单

* 由于要保证幂等性，因此要查询最新的订单状态判断是否需要关单
* 关闭订单后也需要解锁库存，因此发送消息进行库存、会员服务对应的解锁

```java
@Override
public void closeOrder(OrderEntity entity) {
    log.info("\n收到过期的订单信息--准关闭订单:" + entity.getOrderSn());
    // 因为消息发送过来的订单已经是很久前的了，中间可能被改动，因此要查询最新的订单
    OrderEntity orderEntity = this.getById(entity.getId());
    //如果订单还处于新创建的状态，说明超时未支付，进行关单
    if (orderEntity.getStatus() == OrderStatusEnum.CREATE_NEW.getCode()) {
        OrderEntity update = new OrderEntity();
        update.setId(entity.getId());
        update.setStatus(OrderStatusEnum.CANCLED.getCode());
        this.updateById(update);
        // 发送给MQ告诉它有一个订单被自动关闭了
        OrderTo orderTo = new OrderTo();
        BeanUtils.copyProperties(orderEntity, orderTo);
        try {
            // 保证消息 100% 发出去 每一个消息在数据库保存详细信息
            // 定期扫描数据库 将失败的消息在发送一遍
            rabbitTemplate.convertAndSend(RabbitInfo.Order.exchange,
                                          RabbitInfo.Order.baseRoutingKey, orderTo);
        } catch (AmqpException e) {
            // 将没发送成功的消息进行重试发送.
        }
    }
}
```

万一发送失败呢？放入一个数据库，定时任务扫描

要设置Broker落盘才能返回ACK。在OrderRabbitConfig类中有收到ACK和报错的方式

反正有必要还是需要手动ACK

```java
@Service
@RabbitListener(queues = RabbitInfo.Stock.releaseQueue)
public class StockReleaseListener {

    @Autowired
    private WareSkuService wareSkuService;

    /**
	 * 下单成功 库存解锁 接下来业务调用失败
	 *
	 *  只要解锁库存消息失败 一定要告诉服务解锁失败
	 */
    @RabbitHandler
    public void handleStockLockedRelease(StockLockedTo to,
                                         Message message,
                                         Channel channel) throws IOException {
        try {
            wareSkuService.unlockStock(to); // 要根据id
            // 执行成功的 回复 [仅回复自己的消息]
            channel.basicAck(message.getMessageProperties().getDeliveryTag(), false);
        } catch (Exception e) {
            channel.basicReject(message.getMessageProperties().getDeliveryTag(), true);
        }
    }

    /**
	 * 订单关闭后 发送的消息这里接收
	 */
    @RabbitHandler
    public void handleOrderCloseRelease(OrderTo to, Message message,
                                        Channel channel) throws IOException {
        try {
            wareSkuService.unlockStock(to);
            channel.basicAck(message.getMessageProperties().getDeliveryTag(), false);
        } catch (Exception e) {
            channel.basicReject(message.getMessageProperties().getDeliveryTag(), true);
        }
    }
}

```

```java
@Override
public void unlock(OrderTo orderTo) {
    //为防止重复解锁，需要重新查询工作单
    String orderSn = orderTo.getOrderSn();
    WareOrderTaskEntity taskEntity = wareOrderTaskService.getBaseMapper().selectOne((new QueryWrapper<WareOrderTaskEntity>().eq("order_sn", orderSn)));
    //查询出当前订单相关的且处于锁定状态的工作单详情
    List<WareOrderTaskDetailEntity> lockDetails = wareOrderTaskDetailService.list(
        new QueryWrapper<WareOrderTaskDetailEntity>()
        .eq("task_id", taskEntity.getId())
        .eq("lock_status", WareTaskStatusEnum.Locked.getCode()));
    for (WareOrderTaskDetailEntity lockDetail : lockDetails) {
        unlockStock(lockDetail.getSkuId(),lockDetail.getSkuNum(),lockDetail.getWareId(),lockDetail.getId());
    }
}
```



离线笔记均为markdown格式，图片也是云图，10多篇笔记20W字，压缩包仅500k，推荐使用typora阅读。也可以自己导入有道云笔记等软件中

阿里云图床现在**每周得几十元充值**，都要自己往里搭了，麻烦不要散播与转发

![](https://i0.hdslb.com/bfs/album/ff3fb7e24f05c6a850ede4b1f3acc54312c3b0c6.png)

打赏后请主动发支付信息到邮箱  553736044@qq.com  ，上班期间很容易忽略收账信息，邮箱回邮基本秒回

禁止转载发布，禁止散播，若发现大量散播，将对本系统文章图床进行重置处理。

技术人就该干点技术人该干的事



如果帮到了你，留下赞吧，谢谢支持